{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "logits class: tensor([[ 0.0591,  0.0649, -0.0289, -0.0455,  0.0225,  0.0255,  0.0090,  0.0439,\n",
      "          0.0767, -0.0674]], grad_fn=<AddmmBackward0>)\n",
      "Predicted class: tensor([8])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "print(f\"logits class: {logits}\")\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "# print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:  torch.Size([3, 28, 28])\n",
      "flatten_size:  torch.Size([3, 784])\n",
      "hidden1_size:  torch.Size([3, 20])\n",
      "logits_size:  torch.Size([3, 10])\n",
      "tensor([[0.0954, 0.0914, 0.1126, 0.0827, 0.0840, 0.1219, 0.1045, 0.1178, 0.0833,\n",
      "         0.1065],\n",
      "        [0.1059, 0.0792, 0.1133, 0.0848, 0.0911, 0.1253, 0.0988, 0.1253, 0.0720,\n",
      "         0.1042],\n",
      "        [0.0995, 0.0873, 0.1283, 0.0930, 0.0793, 0.1035, 0.0957, 0.1287, 0.0739,\n",
      "         0.1107]], grad_fn=<SoftmaxBackward0>)\n",
      "pred_probab_size:  torch.Size([3, 10])\n",
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 3.1688e-03, -2.7562e-03,  1.7901e-03,  2.0048e-02, -3.2948e-02,\n",
      "          2.6954e-02,  9.1830e-04, -2.4908e-02, -2.2607e-02, -2.3767e-02,\n",
      "          6.9066e-03, -6.2556e-03,  4.8962e-03, -2.3611e-02, -1.1182e-03,\n",
      "          1.7251e-02, -3.3280e-02, -5.3056e-03,  9.3431e-03,  2.4015e-02,\n",
      "          3.9135e-03,  2.9168e-02,  1.9014e-02, -3.0780e-02, -4.1831e-03,\n",
      "         -1.9043e-02,  1.4183e-02, -1.2239e-02, -2.8069e-03,  1.7414e-02,\n",
      "          9.4436e-03,  2.5409e-03,  2.5380e-02,  2.5413e-02, -2.5812e-03,\n",
      "          2.0763e-02,  2.5796e-02,  2.7522e-02, -3.1438e-02, -1.0899e-02,\n",
      "          6.9261e-04, -1.0366e-02,  1.4205e-02,  8.5543e-04,  3.3501e-02,\n",
      "          1.2785e-02,  1.3209e-03,  1.0239e-02, -1.1731e-03, -5.2905e-03,\n",
      "          6.3655e-03, -5.1907e-03,  2.0584e-02, -7.2621e-05,  1.9838e-02,\n",
      "         -6.5278e-05,  2.6681e-02, -2.6458e-02, -2.8800e-02, -8.4805e-03,\n",
      "         -4.3680e-03, -3.3269e-02,  4.7244e-03,  2.5776e-02,  2.1426e-02,\n",
      "         -3.1084e-02,  4.6604e-03,  9.5636e-03,  3.6911e-03, -1.6469e-02,\n",
      "          7.6884e-03,  3.0804e-02,  1.2376e-02,  4.5466e-03, -2.8212e-02,\n",
      "         -2.8851e-02,  2.8574e-02,  1.3525e-02,  2.6058e-02, -5.2335e-04,\n",
      "          1.7564e-02,  3.3501e-02, -1.5532e-02,  3.0548e-02, -3.1114e-02,\n",
      "          3.4080e-02,  1.7659e-02,  2.8520e-02, -3.4366e-02,  1.7595e-02,\n",
      "         -3.9070e-03,  3.1685e-02,  3.3699e-02,  1.4811e-02, -1.8111e-03,\n",
      "         -2.9357e-02, -3.2961e-02, -3.4170e-02, -2.0699e-02,  1.0776e-02,\n",
      "          2.5174e-02, -3.0156e-02,  3.0506e-02, -1.9930e-02, -3.1404e-03,\n",
      "         -1.3182e-02, -1.3747e-02,  3.2569e-02,  2.9712e-02,  1.7464e-03,\n",
      "          8.8065e-03, -3.4322e-02, -2.1377e-02,  2.0045e-02, -1.8377e-02,\n",
      "         -1.1512e-02,  1.1437e-02, -2.4779e-02,  1.3549e-02,  3.6432e-03,\n",
      "         -2.9518e-03, -2.7979e-02,  2.4698e-02,  2.4566e-02, -3.4697e-02,\n",
      "          1.4465e-02,  5.2326e-04,  2.5324e-02,  2.2533e-02,  4.8516e-03,\n",
      "         -2.9117e-02,  1.1920e-02, -1.2415e-02, -2.3128e-02, -3.9512e-03,\n",
      "         -3.1527e-02, -1.1855e-02, -9.2107e-03,  1.4757e-03, -1.0217e-02,\n",
      "         -9.7720e-03,  3.0738e-02,  3.0388e-02, -1.3712e-02,  3.3010e-02,\n",
      "         -3.0578e-02, -1.7024e-02,  8.9986e-03,  2.3460e-02,  1.0096e-02,\n",
      "         -3.0598e-02,  2.1891e-02,  1.0662e-02,  2.1317e-02,  3.2589e-02,\n",
      "          2.4193e-02,  1.6404e-02, -7.9360e-03, -3.1340e-02, -2.6909e-02,\n",
      "          1.3366e-02, -1.4494e-02, -2.8402e-02, -5.6734e-03,  2.8543e-02,\n",
      "          2.6390e-02,  2.5769e-02, -1.5232e-02, -2.4553e-02,  3.0922e-02,\n",
      "          2.0629e-02,  1.9776e-02,  5.2237e-03,  1.8802e-02, -2.6851e-02,\n",
      "         -2.6354e-02,  2.0047e-02, -1.0083e-02,  5.7212e-03, -2.9725e-02,\n",
      "         -2.4216e-02,  2.6773e-02,  1.5878e-02, -3.2656e-02, -9.4573e-03,\n",
      "         -2.7623e-03, -3.3614e-02,  3.3052e-02,  7.2490e-03,  2.9389e-02,\n",
      "         -4.7948e-03,  8.0167e-04, -2.8652e-02,  3.2516e-02, -5.7962e-03,\n",
      "         -2.6848e-02,  3.1074e-02, -7.7193e-03,  5.0473e-04, -1.2105e-02,\n",
      "          2.0714e-02,  1.8873e-02,  1.2849e-02,  4.8759e-04, -8.7463e-03,\n",
      "          1.8867e-02, -1.5163e-02,  2.9673e-03, -2.5126e-02, -1.6478e-02,\n",
      "          2.2002e-02, -2.8261e-02,  3.3214e-02,  2.7277e-02, -6.6188e-03,\n",
      "         -1.0540e-02,  1.2836e-03,  2.8722e-02, -9.5131e-03, -1.1425e-02,\n",
      "         -3.3066e-02,  2.5904e-02, -2.6162e-02,  2.0286e-02,  5.5028e-03,\n",
      "         -2.4123e-02,  3.2200e-02,  3.2707e-04,  7.2944e-03,  1.7610e-03,\n",
      "         -1.5901e-02, -1.0612e-02, -2.0955e-02, -9.6490e-03, -8.3309e-03,\n",
      "          3.5640e-02,  3.3616e-02,  7.6299e-03, -7.8622e-03,  1.5220e-03,\n",
      "         -8.3875e-03,  1.7110e-03, -2.6999e-02,  8.8522e-03,  1.0427e-02,\n",
      "         -1.3758e-02, -9.3049e-03,  4.5519e-03, -2.0057e-02,  2.3833e-02,\n",
      "          2.0472e-02, -2.6827e-02, -1.0821e-02, -6.4696e-03, -2.3133e-02,\n",
      "          9.3777e-03, -2.7944e-02,  3.2599e-02,  5.4595e-03, -2.3400e-02,\n",
      "          2.9262e-02,  2.5616e-02, -2.2091e-02, -1.9290e-02, -3.1041e-02,\n",
      "          4.1433e-03,  6.1533e-03,  3.5403e-02,  2.0695e-03, -9.4034e-03,\n",
      "          5.0620e-03, -9.2078e-04, -9.4210e-03, -3.4982e-03,  3.1415e-02,\n",
      "          1.4442e-02, -3.1091e-02, -8.0982e-04, -2.8645e-02, -3.1793e-02,\n",
      "         -2.3109e-02, -3.0292e-02,  1.0638e-02, -2.9827e-02,  2.3473e-02,\n",
      "          1.4799e-02,  1.4449e-02, -3.5182e-02,  2.0764e-02,  2.7504e-02,\n",
      "         -1.9401e-02,  2.7189e-02, -3.4476e-02,  5.8485e-03, -1.6314e-02,\n",
      "          2.1828e-02,  7.7523e-03,  2.5103e-02, -6.0902e-03,  1.6056e-02,\n",
      "         -1.8482e-02,  3.4549e-02, -1.8001e-02, -1.2987e-02,  3.2405e-02,\n",
      "          3.3526e-02, -3.4276e-02, -1.4228e-02,  2.4435e-02, -2.1893e-02,\n",
      "          2.6385e-02, -1.1663e-03, -1.3755e-02, -3.8154e-03, -1.8017e-02,\n",
      "          2.8624e-02,  1.4686e-02, -1.3868e-02, -2.7163e-02, -1.7555e-02,\n",
      "          5.3006e-03, -1.6697e-02,  3.3979e-02,  8.5426e-03, -2.2254e-02,\n",
      "         -1.0181e-02, -1.4670e-02, -2.6370e-02,  9.1578e-03,  2.4105e-02,\n",
      "         -8.8302e-04,  1.5640e-02, -2.1347e-02,  1.2136e-02,  2.2026e-02,\n",
      "         -1.9339e-02, -1.2150e-02, -3.5603e-03, -7.9908e-03,  2.7575e-03,\n",
      "          6.1249e-03, -2.8796e-02, -2.7806e-02, -9.7853e-03,  1.1019e-02,\n",
      "         -3.3538e-02,  1.7749e-02,  1.1483e-02,  3.1660e-02,  1.7395e-02,\n",
      "         -2.6212e-03,  3.2212e-02,  2.5838e-02,  3.0039e-02,  1.6184e-02,\n",
      "         -9.6552e-03,  3.2633e-02,  1.4016e-02, -3.2584e-02, -3.4483e-02,\n",
      "          5.5915e-03, -2.6544e-02, -1.0447e-02, -3.1073e-02,  2.0776e-02,\n",
      "          6.3337e-03, -2.7093e-02, -4.8559e-03, -2.2372e-02,  2.9312e-02,\n",
      "          3.4877e-02,  1.5607e-02,  2.2745e-03, -2.3199e-02, -8.3925e-03,\n",
      "          2.9577e-02,  2.6981e-02,  1.3815e-02, -2.6780e-02,  2.9413e-02,\n",
      "         -3.4854e-03, -3.3891e-02, -2.2970e-02,  9.2732e-03, -2.1607e-02,\n",
      "          2.8891e-02,  2.1855e-02,  4.9942e-03, -2.9769e-02, -3.6287e-04,\n",
      "          1.9516e-02,  3.3523e-03, -7.8110e-03, -2.2003e-02,  9.2614e-03,\n",
      "         -3.3219e-02,  9.2693e-03,  2.6930e-02,  5.4083e-03,  2.3936e-02,\n",
      "         -2.4900e-02,  9.0737e-03, -3.1886e-02, -2.6304e-02, -2.4025e-02,\n",
      "          2.7010e-02, -2.8771e-02, -3.3997e-03,  2.8092e-02,  6.1622e-03,\n",
      "          2.8552e-02, -1.6128e-02, -2.3085e-02, -1.2431e-02,  1.6265e-02,\n",
      "          2.0608e-02,  1.1003e-02, -1.2365e-02, -3.0960e-02,  2.3399e-02,\n",
      "         -1.2967e-02,  1.6802e-02, -7.5315e-03, -3.1797e-02, -3.3631e-02,\n",
      "         -3.1105e-03, -2.8629e-02,  2.7183e-03,  3.0633e-02,  8.5829e-03,\n",
      "          7.7227e-03, -2.9151e-02, -1.6297e-02,  2.5721e-02, -3.8957e-04,\n",
      "          3.5454e-02, -2.1503e-02,  1.4472e-02,  1.9606e-02,  1.1269e-02,\n",
      "          8.0036e-03,  2.7806e-02,  1.7808e-02,  1.8024e-02,  1.4785e-02,\n",
      "          1.4184e-02, -3.4076e-02,  2.5554e-02,  2.4409e-02,  1.8807e-02,\n",
      "          8.4838e-03,  2.5964e-02,  7.7630e-03, -2.6047e-02, -4.6318e-03,\n",
      "         -5.3412e-03,  2.5620e-02, -2.6868e-02, -2.2147e-02, -3.2272e-02,\n",
      "          1.8267e-02, -1.2455e-03,  5.3065e-03, -3.4285e-02, -1.6958e-02,\n",
      "          2.6599e-02,  3.0191e-02, -3.3141e-03, -3.4623e-02,  1.3693e-02,\n",
      "         -1.7177e-02, -2.1574e-02,  3.2045e-02,  8.7740e-03, -2.7875e-02,\n",
      "         -7.0144e-03, -3.4541e-03, -1.7871e-02, -1.4340e-02,  1.7439e-02,\n",
      "         -3.1955e-02, -1.4882e-02, -8.8723e-03, -2.1368e-02,  5.3762e-03,\n",
      "          5.7877e-03, -1.2920e-02,  1.4201e-02,  1.2813e-02, -3.5254e-02,\n",
      "         -2.9907e-02,  1.2160e-02, -3.1900e-02, -1.5352e-04, -8.9138e-03,\n",
      "          7.2287e-03,  2.5659e-02,  2.0506e-02,  2.7187e-02,  2.9085e-02,\n",
      "         -1.8692e-02, -1.7577e-02, -2.9930e-02, -1.5839e-02, -3.4895e-02,\n",
      "         -1.8563e-02, -2.4913e-02,  1.9360e-02,  4.3530e-03,  3.1123e-02,\n",
      "          1.1683e-02, -2.8662e-02, -7.2140e-03,  1.6496e-02,  3.3885e-02,\n",
      "         -2.7845e-02,  1.8779e-02, -2.3510e-02,  2.6484e-03, -1.7192e-03,\n",
      "         -2.2659e-02, -9.4689e-03, -2.5720e-02,  1.9775e-02, -5.8481e-03,\n",
      "         -2.0180e-02, -3.5161e-03, -1.1827e-02, -1.7338e-02,  2.5737e-03,\n",
      "          1.7287e-02, -2.8856e-02,  4.7498e-04, -2.5483e-02,  1.4516e-02,\n",
      "         -9.7810e-03,  1.7834e-03,  2.0655e-03,  3.4544e-03,  1.7552e-02,\n",
      "         -3.5011e-02,  2.2975e-03, -6.6897e-03,  7.0715e-03, -2.1642e-02,\n",
      "         -1.0963e-02, -2.1419e-02,  1.9840e-02,  2.6314e-02, -1.5878e-02,\n",
      "          2.5001e-02,  3.9733e-04, -4.5012e-03, -2.8939e-02, -2.3665e-02,\n",
      "         -2.6898e-02,  1.0034e-02, -2.1234e-02,  2.6915e-02,  1.2718e-02,\n",
      "          6.7676e-04, -2.0729e-02,  6.1186e-03,  2.4835e-02, -1.8761e-02,\n",
      "          1.7237e-02, -2.7683e-02, -2.3083e-02,  7.2180e-03,  1.2708e-02,\n",
      "          2.2247e-02, -1.4864e-02, -2.0938e-02,  2.6564e-02,  3.2084e-02,\n",
      "          9.1544e-03,  4.6241e-03,  2.1988e-02,  3.4276e-02, -1.9646e-02,\n",
      "          2.5566e-03,  3.7933e-03,  1.7946e-02, -5.9313e-03,  3.4393e-02,\n",
      "          6.4522e-03,  3.5040e-02, -1.7123e-02, -2.5901e-02,  3.0596e-02,\n",
      "         -1.9540e-02,  2.0057e-02,  1.8930e-02, -2.5714e-02,  1.6039e-03,\n",
      "          3.2727e-03, -2.2081e-02, -2.5716e-02, -8.3266e-03,  1.3014e-02,\n",
      "         -1.1235e-02, -9.1631e-04,  3.0721e-02, -1.7391e-03,  3.0634e-02,\n",
      "         -1.4609e-02, -5.8928e-03,  1.5286e-02, -2.2817e-02,  9.8078e-03,\n",
      "         -3.5709e-02, -1.4077e-02, -2.1490e-02,  3.2029e-02,  3.8579e-03,\n",
      "          1.4310e-02,  8.4719e-03,  1.0260e-02,  1.4646e-02,  2.0644e-02,\n",
      "         -7.8947e-03,  1.8228e-04,  1.3304e-02,  1.6480e-02, -1.6640e-02,\n",
      "         -2.1374e-02, -5.6932e-03,  2.0144e-02,  1.2713e-02,  1.0627e-02,\n",
      "         -2.7184e-02,  1.9180e-03, -3.7041e-03,  2.8471e-02, -2.8502e-02,\n",
      "          2.1979e-02,  1.7034e-02, -4.0900e-03, -1.4658e-03, -2.2132e-02,\n",
      "         -8.8960e-03, -1.1262e-02,  4.4867e-04,  3.5238e-02,  1.6400e-02,\n",
      "         -2.2765e-02,  4.1727e-03,  2.1411e-02, -1.6972e-02,  1.4339e-02,\n",
      "          4.4793e-03, -1.4490e-02, -1.8577e-02,  2.0841e-02, -3.1373e-02,\n",
      "          3.4732e-02,  1.7731e-02,  2.8692e-02,  2.0524e-02, -5.5487e-03,\n",
      "         -7.6600e-03,  1.6241e-02, -6.2974e-03, -1.2802e-02,  1.4482e-02,\n",
      "         -2.4758e-02,  3.0365e-02,  3.4115e-02,  3.3060e-02,  3.3161e-03,\n",
      "          1.4902e-02, -1.7797e-02,  1.6820e-02, -2.3360e-03, -1.6177e-03,\n",
      "          1.3795e-02, -7.6631e-03,  1.9906e-02, -1.0737e-02,  1.6107e-02,\n",
      "         -2.9445e-02,  3.5139e-02, -1.1434e-02, -2.7230e-02,  1.6131e-02,\n",
      "          2.0258e-02,  2.4458e-02, -1.2609e-02,  6.7847e-03,  1.8921e-02,\n",
      "         -3.8271e-03, -2.0086e-02, -1.8670e-02,  2.8848e-02,  1.1628e-02,\n",
      "         -6.2058e-03,  3.3227e-02,  3.4049e-02,  2.0935e-02,  3.5611e-03,\n",
      "         -3.0607e-02,  3.0692e-02, -1.0430e-02,  1.2989e-02, -2.6021e-03,\n",
      "          1.4797e-02,  2.0488e-02, -2.4696e-02, -2.8838e-02, -3.1523e-03,\n",
      "          1.7042e-02, -2.7477e-02, -2.3659e-02, -2.3772e-02,  2.4106e-02,\n",
      "          5.1382e-03, -2.3718e-02, -3.1396e-02, -1.1712e-02, -3.5125e-02,\n",
      "         -3.1531e-02,  2.0167e-02, -2.7470e-02, -3.1035e-02, -8.5917e-04,\n",
      "          4.5224e-03, -1.9357e-02,  1.6959e-02, -4.9523e-04,  2.5171e-03,\n",
      "          3.4795e-03,  1.1790e-02,  3.3771e-02,  1.1030e-02, -1.2951e-02,\n",
      "          1.2878e-02, -1.0271e-02,  3.1501e-03, -2.6293e-02,  1.7849e-02,\n",
      "          1.0594e-02,  9.9629e-03, -2.5180e-02,  2.1220e-02, -1.3825e-02,\n",
      "          1.0732e-02, -7.6032e-03, -2.1583e-02, -9.7414e-03, -1.1349e-02,\n",
      "          2.0874e-02, -7.2609e-03,  9.7122e-04,  1.0825e-02,  3.5174e-03,\n",
      "          1.1327e-02,  2.5553e-04, -3.0614e-02,  3.1497e-02, -1.3525e-02,\n",
      "         -1.6853e-02,  1.5200e-02,  2.7270e-02, -1.3168e-02,  3.4414e-02,\n",
      "         -2.0778e-03, -4.5755e-03, -3.5684e-02,  1.6823e-02,  1.2579e-02,\n",
      "         -2.1199e-02, -9.4788e-03, -1.9512e-02,  3.0311e-02, -2.6374e-02,\n",
      "          2.8660e-02, -2.3845e-03, -3.0568e-02,  6.1992e-03, -2.2112e-02,\n",
      "          6.0415e-03,  7.4173e-03, -1.3640e-02,  3.4793e-02]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0305], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-4.3546e-02, -4.0282e-02, -8.1054e-04,  2.3016e-02,  2.1614e-02,\n",
      "          7.0697e-03, -3.8471e-02,  1.7951e-02, -1.1135e-03, -1.5949e-02,\n",
      "         -3.5093e-02,  3.9668e-02, -3.4494e-02, -2.9318e-02, -3.1925e-02,\n",
      "         -1.4363e-02,  4.3099e-02, -1.5627e-02, -2.5402e-03,  2.5038e-02,\n",
      "          8.8460e-03,  2.7489e-02, -3.9711e-02, -3.1325e-02, -3.6603e-02,\n",
      "          1.4088e-02, -9.2699e-03,  2.0415e-02,  3.9492e-02, -2.0584e-02,\n",
      "         -4.1328e-03, -3.2057e-02,  2.8042e-02, -2.8488e-02, -1.6511e-02,\n",
      "         -2.6168e-02, -5.7964e-03, -3.3909e-02,  1.7347e-02, -3.8596e-02,\n",
      "         -4.2790e-02, -1.6802e-02,  3.8907e-02, -3.4467e-02,  4.3774e-02,\n",
      "         -2.7853e-02,  3.1537e-02,  3.3741e-02,  1.4639e-02,  1.1567e-02,\n",
      "         -3.7223e-02,  2.7310e-02, -4.0977e-02, -2.5572e-02, -1.8869e-02,\n",
      "          2.9067e-02, -3.5145e-02,  3.5302e-02, -2.7464e-02,  3.3930e-02,\n",
      "         -4.2911e-02,  8.6302e-03, -6.0645e-03,  4.1881e-02, -3.1444e-02,\n",
      "         -2.2912e-02,  4.1757e-02,  4.2350e-02, -3.4165e-02,  3.1959e-02,\n",
      "          3.3450e-02, -1.4620e-02, -2.1445e-02,  4.1071e-02, -1.8656e-02,\n",
      "         -3.8166e-03,  1.5004e-02, -4.8896e-03,  3.5439e-02,  3.4178e-02,\n",
      "          4.0542e-02, -2.0929e-02, -8.9802e-03,  3.9800e-02,  3.6466e-02,\n",
      "          2.6128e-02, -3.1394e-02, -1.2168e-02,  2.5906e-02,  3.5155e-02,\n",
      "          1.5150e-02, -2.2848e-02, -3.7712e-02, -9.1087e-03, -2.3620e-02,\n",
      "         -3.2768e-02, -2.0164e-02,  2.4169e-02, -5.5574e-03, -3.4713e-02,\n",
      "          3.5413e-02,  1.5058e-02,  3.9330e-02, -1.5578e-02,  2.7919e-02,\n",
      "          1.7826e-02,  2.8161e-02,  1.8392e-02, -3.3255e-02,  3.8804e-02,\n",
      "          4.5304e-04, -4.3652e-02, -1.0830e-02,  5.9338e-03,  3.6239e-02,\n",
      "         -2.8152e-02, -4.1755e-02,  1.0002e-03, -6.8941e-03, -1.4299e-02,\n",
      "         -3.6164e-02,  8.5768e-03,  3.0619e-02, -4.1370e-02,  1.6017e-02,\n",
      "         -5.8236e-03, -2.9458e-02, -1.5921e-02,  1.3332e-02,  4.2325e-02,\n",
      "         -1.6164e-02, -3.2841e-02,  2.8559e-02,  3.6652e-02,  1.2244e-02,\n",
      "          3.6195e-02,  2.1469e-02, -3.9914e-02,  3.8470e-02, -3.6039e-02,\n",
      "          1.2245e-02, -1.8794e-03, -3.4818e-02,  1.3653e-02,  3.4132e-02,\n",
      "         -2.3042e-02,  2.4340e-02,  1.7514e-02,  7.1384e-03, -3.9446e-02,\n",
      "         -2.2473e-02,  5.3759e-03, -2.7461e-02,  4.3091e-02,  3.5223e-02,\n",
      "          3.0041e-02,  5.1702e-03,  1.7993e-02,  2.6823e-02,  4.0630e-02,\n",
      "          3.3213e-02, -4.2711e-02, -6.4671e-04,  2.3337e-02, -7.3643e-03,\n",
      "          1.3966e-02,  1.8882e-02,  1.0025e-02, -8.3280e-03,  3.1630e-02,\n",
      "          6.0166e-03,  3.7648e-02,  4.3744e-02,  2.2052e-03, -2.1845e-02,\n",
      "          4.0665e-02,  3.0324e-02, -1.8725e-02,  3.4208e-02,  3.6750e-02,\n",
      "          2.9783e-02, -5.4322e-03, -1.7989e-02,  3.7383e-02,  1.4149e-02,\n",
      "          2.4358e-02,  2.0518e-02,  2.2299e-03,  1.0513e-02, -1.9551e-02,\n",
      "          3.2675e-02,  1.5927e-02,  3.1939e-02, -7.2584e-03, -2.1378e-02,\n",
      "          4.3568e-02,  2.4071e-02,  1.9772e-02,  2.0677e-03,  1.4028e-02,\n",
      "         -6.2297e-03, -1.0213e-02,  2.2001e-02,  1.4390e-02,  7.7665e-03,\n",
      "         -3.8304e-02,  3.1271e-02, -1.9367e-02,  2.9504e-02,  2.0941e-02,\n",
      "         -1.6223e-02,  1.1320e-02, -2.0457e-02, -1.6864e-02, -1.3042e-02,\n",
      "         -1.1202e-02, -3.4982e-02, -3.1936e-02, -3.7243e-02, -8.4342e-03,\n",
      "         -3.6025e-04,  2.4516e-02,  3.0133e-02, -2.2354e-02,  2.4738e-02,\n",
      "         -2.1139e-02,  2.4818e-02, -2.0274e-02,  3.8211e-02, -4.0822e-02,\n",
      "         -1.2798e-02,  3.6748e-03, -1.6354e-02, -8.0485e-03, -1.0690e-03,\n",
      "          2.1618e-02, -7.7353e-03, -9.0541e-04, -3.5425e-02, -1.9906e-02,\n",
      "          3.7381e-02,  2.9147e-02,  1.0951e-02,  1.4914e-02, -4.0515e-03,\n",
      "         -2.8587e-02,  3.3846e-02,  4.8658e-03, -5.1063e-04,  1.1543e-02,\n",
      "          6.1435e-04,  3.4881e-02, -4.1515e-02, -2.0508e-02, -4.0206e-02,\n",
      "         -2.5311e-02, -3.2550e-02, -2.0536e-02,  2.1907e-02,  3.0476e-02,\n",
      "          1.9614e-02, -7.3257e-03,  8.6764e-03,  5.3499e-03,  3.0370e-02,\n",
      "          3.5015e-02,  2.6820e-02,  2.3366e-02,  3.7179e-02, -3.3187e-02,\n",
      "         -1.9627e-02,  3.3771e-02, -2.3102e-02, -1.6931e-03, -3.3449e-02,\n",
      "          2.6290e-02,  6.0066e-03, -3.3955e-02,  2.9573e-02, -2.1907e-02,\n",
      "          3.7122e-02,  3.4601e-02, -1.3074e-02, -2.7567e-02, -1.8533e-02,\n",
      "          3.7407e-03, -1.2933e-02,  1.2885e-02, -3.4814e-02, -4.2098e-02,\n",
      "         -1.9516e-02,  4.0112e-02, -3.7121e-02, -7.6652e-03,  1.5316e-02,\n",
      "         -3.3986e-02,  1.5224e-02,  3.7053e-03, -3.0854e-02,  9.2856e-03,\n",
      "         -1.4499e-03,  2.2236e-02,  4.8437e-03, -1.6972e-02, -1.2205e-02,\n",
      "         -1.0748e-02, -1.9700e-02, -1.0725e-02, -4.3438e-03, -3.7926e-02,\n",
      "         -3.0577e-02, -2.1542e-02, -2.0669e-02,  2.9698e-02,  1.5033e-02,\n",
      "          1.6405e-02,  2.1678e-02, -1.6548e-02, -1.6676e-02, -3.2171e-02,\n",
      "         -1.2941e-02, -3.4603e-02,  2.1016e-03,  2.0192e-02,  3.9917e-02,\n",
      "         -1.8977e-02,  3.0243e-02, -2.9533e-02, -4.2002e-02, -2.0212e-02,\n",
      "         -1.2298e-03, -3.8163e-02, -3.1775e-02,  3.1742e-02,  4.3428e-02,\n",
      "         -3.7488e-02, -3.5947e-02, -2.2239e-03, -1.7067e-02,  2.7908e-02,\n",
      "         -2.6288e-02,  3.2814e-02,  2.2649e-02, -4.0915e-02, -7.1800e-03,\n",
      "         -3.5277e-02, -5.2957e-03, -3.9193e-02, -3.4603e-02, -3.7206e-02,\n",
      "         -1.3529e-02, -1.1282e-02, -2.6731e-02, -3.1045e-02, -1.8501e-02,\n",
      "          1.2939e-02,  4.3917e-02,  9.6379e-03, -2.1217e-03, -1.1107e-02,\n",
      "         -1.7578e-02,  3.3661e-02,  2.3095e-03,  1.0326e-02,  2.0283e-02,\n",
      "         -1.3676e-02, -3.5979e-05, -3.8930e-02, -4.0519e-02, -1.9532e-02,\n",
      "          8.5408e-03,  1.9254e-02,  2.8650e-02, -1.7126e-02, -3.3704e-02,\n",
      "         -7.2776e-03,  4.5533e-03, -8.7415e-03,  1.2427e-02, -1.2920e-02,\n",
      "          1.9745e-03,  9.3204e-03,  1.9179e-02,  2.9623e-02,  3.3578e-02,\n",
      "         -1.6212e-02, -2.6965e-02,  4.1836e-02, -2.6055e-02,  4.0817e-02,\n",
      "         -3.3256e-02, -7.4457e-03,  4.8364e-04, -2.9272e-02, -2.1432e-02,\n",
      "         -3.8080e-02, -1.1747e-02, -1.4310e-02,  3.6268e-02,  1.6729e-02,\n",
      "          9.0730e-03, -3.7422e-02,  4.0468e-02,  3.3964e-02, -3.2309e-02,\n",
      "          3.9869e-02, -5.8379e-03,  2.6432e-02,  3.5316e-02, -3.7300e-02,\n",
      "          1.0783e-02, -1.7927e-02,  4.3016e-02,  1.8053e-02,  2.0061e-02,\n",
      "         -2.9709e-02,  3.1267e-02, -1.6166e-02, -1.6900e-02, -2.8008e-02,\n",
      "          2.5631e-02, -8.5391e-03, -2.9465e-02,  2.9750e-02, -3.9412e-02,\n",
      "          6.7657e-03, -1.3011e-02, -1.7475e-02,  4.0072e-02, -1.0273e-02,\n",
      "         -3.0340e-02,  2.1878e-02, -3.7102e-02, -2.3056e-02, -2.4961e-02,\n",
      "         -9.9757e-03, -2.5513e-02, -2.2946e-02, -4.0804e-02,  3.0597e-02,\n",
      "         -3.9097e-02,  2.0623e-02, -1.1330e-02, -1.7587e-02, -9.1967e-03,\n",
      "          1.4801e-02,  1.0506e-03,  2.7427e-03, -2.0813e-02,  4.2342e-02,\n",
      "         -3.5703e-03,  4.2714e-02, -3.5763e-02,  3.7050e-02,  3.9718e-02,\n",
      "          3.3010e-02,  2.9605e-02, -1.8589e-06, -3.3613e-02, -2.7118e-03,\n",
      "         -1.1646e-02,  1.1921e-02, -7.4911e-03, -7.9013e-03, -2.9263e-02,\n",
      "          2.6301e-02, -3.2820e-02, -2.8166e-03, -3.0826e-02, -3.6476e-02,\n",
      "         -5.4783e-03,  3.3007e-02, -3.8054e-02,  1.1328e-02,  1.4914e-02,\n",
      "          4.1505e-02, -3.2822e-02,  4.3101e-02, -2.9006e-02,  1.2033e-02,\n",
      "         -1.7008e-02,  4.2363e-02,  4.3402e-02, -3.8032e-02, -7.4069e-03,\n",
      "          3.0839e-02, -4.0259e-02,  9.6539e-03,  1.0469e-02,  4.1278e-02,\n",
      "          2.9473e-02,  3.6439e-02,  3.8579e-02,  3.8944e-02,  1.2051e-02,\n",
      "          2.5634e-02, -2.5634e-02,  8.3388e-03, -1.4027e-02, -4.3629e-02,\n",
      "          1.5263e-02,  1.2777e-02,  4.0194e-02,  1.9739e-02,  1.4646e-02,\n",
      "         -1.7501e-03,  2.2259e-02, -3.6880e-02, -2.6633e-02, -1.8327e-02,\n",
      "          2.1484e-03,  3.1920e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0275], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-3.8285e-02,  1.3610e-02, -4.2302e-02,  2.5238e-02, -2.5199e-02,\n",
      "          1.8032e-02,  9.6118e-03,  4.2578e-02, -4.8738e-03, -2.1679e-02,\n",
      "          1.6172e-02, -1.3446e-02, -1.0766e-02, -3.2101e-02, -3.4174e-02,\n",
      "         -7.7603e-03, -1.1110e-02,  2.7482e-02, -4.3672e-02,  4.0636e-02,\n",
      "         -7.5535e-03, -7.4963e-03,  4.0864e-02,  2.2521e-02,  3.9957e-02,\n",
      "         -1.0479e-02, -1.0911e-02,  3.3343e-02, -4.0385e-02, -8.0444e-03,\n",
      "          1.4858e-02, -6.7368e-05, -1.4274e-02, -3.2436e-02,  2.7282e-02,\n",
      "         -2.0526e-02,  2.5527e-02, -1.2680e-02,  1.8846e-03,  6.7033e-03,\n",
      "         -2.3623e-02,  1.5370e-02, -4.2251e-02,  3.2452e-02,  3.6482e-02,\n",
      "         -8.2292e-03,  3.6831e-02,  5.5846e-05,  3.8059e-02,  4.1786e-03,\n",
      "          1.0621e-02, -3.8713e-02, -7.7902e-03,  3.9471e-02, -3.0455e-02,\n",
      "          5.9109e-03,  3.8973e-02,  2.9016e-02,  2.9520e-02, -2.7720e-02,\n",
      "         -1.9321e-02, -6.9225e-03,  3.7179e-02, -3.1155e-02, -3.0818e-02,\n",
      "         -1.6154e-02,  6.9293e-03, -3.0663e-03,  8.7794e-03, -8.1218e-03,\n",
      "          3.2099e-02,  3.3492e-02, -1.6102e-02,  3.2788e-02,  1.2580e-02,\n",
      "          3.8162e-02,  2.7503e-02, -6.7060e-03, -3.0196e-02,  6.3301e-04,\n",
      "          9.8824e-03,  3.1202e-02, -3.4628e-02, -1.5804e-02, -1.1645e-02,\n",
      "         -2.6127e-03, -3.7756e-02, -2.4441e-02,  3.9494e-02,  3.2829e-02,\n",
      "          1.5002e-03, -1.4993e-02,  4.4795e-03, -3.9565e-03,  2.1720e-02,\n",
      "         -2.2692e-02,  1.2252e-02, -2.5375e-02, -4.1436e-03,  2.5691e-02,\n",
      "          1.8048e-02,  2.2195e-02,  2.3201e-02, -1.1432e-02,  2.1500e-02,\n",
      "         -5.6942e-03,  1.3298e-02,  4.0385e-02, -3.6624e-02, -3.8918e-04,\n",
      "         -9.0654e-03, -1.5521e-03, -1.1587e-02, -6.7614e-03, -2.5063e-03,\n",
      "         -8.2219e-03, -4.3451e-02,  6.0857e-03,  2.9149e-02,  4.9576e-04,\n",
      "         -2.0452e-02,  1.1686e-02, -2.9234e-02,  2.3001e-02, -1.9643e-02,\n",
      "          3.1725e-02, -4.2500e-02,  3.0994e-02, -5.4628e-03, -1.9433e-02,\n",
      "         -2.1539e-02,  1.8225e-02, -2.3771e-03,  2.8018e-02,  2.3839e-03,\n",
      "          3.1293e-02, -1.7683e-02, -2.2981e-02, -2.5503e-02,  3.9686e-02,\n",
      "         -4.3766e-02, -3.4290e-02,  1.7422e-02, -6.6852e-03,  4.0518e-02,\n",
      "         -3.3941e-02,  1.1337e-02, -7.6886e-03, -3.2281e-02, -3.2739e-03,\n",
      "         -1.0745e-02,  2.5247e-02, -2.5621e-02, -7.4402e-03,  3.7992e-02,\n",
      "          3.2634e-02,  1.4307e-02, -1.1785e-02, -6.6294e-04, -7.5594e-03,\n",
      "         -6.0297e-03, -2.9674e-02,  4.0219e-02,  1.0854e-02,  2.2468e-02,\n",
      "          1.7421e-02, -3.3494e-02,  2.5202e-03, -1.9879e-02,  3.0635e-02,\n",
      "          2.2200e-02,  2.5928e-02, -1.5846e-02,  3.1081e-02, -2.5044e-03,\n",
      "         -1.3918e-02,  6.5216e-03, -9.4489e-03,  8.8492e-03,  1.5868e-02,\n",
      "          7.1374e-03,  2.7548e-02,  1.9610e-02, -3.5526e-02, -3.3371e-03,\n",
      "         -2.2346e-02,  2.8888e-02,  2.2209e-02,  4.2086e-02,  2.7827e-02,\n",
      "         -5.4745e-03,  3.1694e-02, -3.9235e-02, -3.9439e-02,  2.4375e-02,\n",
      "         -5.3977e-03,  3.1361e-02,  2.7606e-02, -1.8826e-02, -3.5825e-02,\n",
      "         -3.3897e-02, -4.3119e-02, -3.3423e-02, -4.4569e-05,  5.1798e-03,\n",
      "         -3.4490e-02,  7.4968e-04, -4.8684e-03,  2.1420e-02,  3.8969e-02,\n",
      "         -2.8231e-02, -1.3344e-02,  3.9297e-03, -2.3332e-02,  2.0441e-02,\n",
      "          2.7634e-02,  2.7227e-02, -4.2779e-03,  3.9715e-04,  1.6147e-03,\n",
      "         -1.8845e-02, -2.8040e-02, -2.4936e-02,  1.0398e-02,  1.3642e-02,\n",
      "         -2.4887e-02, -3.9834e-02,  9.3638e-03, -1.1584e-02, -4.0643e-02,\n",
      "         -4.7573e-03, -1.8704e-02, -2.4298e-02,  3.0911e-02,  1.4487e-02,\n",
      "         -1.0081e-02,  1.0334e-02, -3.8454e-02, -3.4396e-02, -3.5928e-02,\n",
      "          2.4492e-02,  2.8962e-02,  7.8617e-03, -5.8521e-03,  3.0506e-02,\n",
      "         -1.3265e-02,  4.4181e-03,  2.5429e-02, -3.6366e-02,  4.2755e-02,\n",
      "          1.3855e-02, -2.4511e-02, -1.4280e-02,  1.8575e-02, -1.3356e-02,\n",
      "         -3.1501e-02,  3.7084e-02, -3.2740e-02, -5.5536e-03,  2.9464e-02,\n",
      "         -1.3881e-02,  4.0557e-02,  9.8548e-03, -5.3368e-03,  3.3519e-02,\n",
      "         -2.6709e-02, -1.3564e-03,  1.3683e-02, -2.4599e-02, -3.1939e-03,\n",
      "          9.7684e-03, -3.1674e-02, -4.2620e-02, -1.1732e-02, -3.8157e-02,\n",
      "          3.1283e-02,  2.5138e-02,  5.8656e-03, -1.8050e-02, -7.6897e-03,\n",
      "          3.0627e-02,  1.7851e-02,  4.1172e-02,  1.3111e-02, -9.8308e-03,\n",
      "          1.9725e-02,  3.5646e-02, -2.0320e-03, -1.1485e-03, -2.7764e-02,\n",
      "         -1.5119e-02, -3.6141e-02, -4.3745e-02,  3.5923e-03, -2.3682e-02,\n",
      "          1.3935e-02,  2.0065e-02, -1.5297e-02, -3.0501e-02,  3.3766e-02,\n",
      "         -1.7760e-02,  3.5509e-02, -4.3198e-02, -4.3292e-02, -2.1217e-02,\n",
      "         -2.2744e-02,  2.8960e-02,  2.5717e-02,  4.1924e-02,  3.7329e-02,\n",
      "          7.0410e-03, -3.7840e-02, -1.2933e-02, -4.0287e-03,  1.3748e-03,\n",
      "         -3.2048e-03, -3.9609e-02,  3.1213e-02,  3.3491e-02,  1.4756e-02,\n",
      "         -3.4256e-02,  7.4799e-03, -3.8423e-02,  2.7859e-02, -2.2137e-02,\n",
      "         -6.3683e-03, -3.5609e-02,  8.8107e-03,  2.7186e-02, -4.1804e-02,\n",
      "         -4.1260e-03,  3.3723e-02, -4.2708e-02,  6.4224e-03,  1.3467e-02,\n",
      "          4.2133e-02,  2.0079e-02, -3.3093e-02, -8.5928e-03,  2.6420e-02,\n",
      "         -2.2440e-02, -1.1070e-04, -1.7562e-03, -9.9784e-03,  1.1621e-02,\n",
      "          1.0257e-02,  9.7878e-03,  8.4566e-03, -1.4418e-02,  3.7957e-02,\n",
      "          1.1249e-03,  5.6283e-04,  3.0035e-03,  1.7801e-02,  2.1098e-02,\n",
      "         -4.0439e-02, -1.3133e-02, -3.3049e-02,  3.5432e-02,  4.1810e-02,\n",
      "          4.6308e-03, -5.8744e-04, -1.8059e-02,  3.7865e-02,  2.5612e-02,\n",
      "         -1.0655e-02, -1.3632e-02, -2.3526e-02,  5.0924e-03, -3.1304e-02,\n",
      "         -2.0828e-02,  1.5970e-02,  4.4178e-02, -1.0763e-02,  2.2898e-02,\n",
      "          2.9836e-03, -2.1831e-03, -1.3509e-02,  2.6423e-02, -2.8037e-02,\n",
      "         -6.1224e-04,  9.3285e-03, -1.4939e-02,  1.2572e-02,  1.1633e-02,\n",
      "         -1.7216e-03,  4.0727e-02, -1.5385e-02, -2.8552e-02, -1.2956e-02,\n",
      "         -1.0693e-02,  2.1924e-02,  9.4028e-03, -2.8907e-02,  3.4850e-02,\n",
      "          2.3879e-02, -4.3307e-02, -1.2625e-02, -2.7782e-02, -3.6535e-02,\n",
      "         -2.8170e-02, -4.4069e-02,  9.0387e-03, -1.3815e-03, -7.7772e-03,\n",
      "          5.7067e-03,  2.8792e-02,  2.8028e-02,  6.0703e-03, -3.7553e-02,\n",
      "          9.7356e-03, -5.4560e-03,  1.4456e-02,  1.4166e-02,  1.8709e-02,\n",
      "         -3.2389e-02,  1.4312e-02,  2.7665e-02, -3.7692e-02, -2.3187e-02,\n",
      "          4.3389e-02, -1.8860e-02, -1.4790e-02,  2.3569e-02, -2.7089e-02,\n",
      "         -1.0428e-02,  3.4426e-02,  3.7875e-03,  1.7635e-02, -3.6039e-02,\n",
      "          1.5226e-02, -1.7540e-02,  3.1428e-02, -1.4466e-02,  1.3895e-02,\n",
      "          3.9138e-02, -1.9850e-02,  1.5906e-02,  3.4072e-02,  1.4846e-02,\n",
      "          3.8400e-02,  2.1478e-02,  3.9971e-02, -2.1783e-02,  2.8799e-02,\n",
      "         -1.9486e-02, -2.5743e-02, -2.9382e-03,  3.9735e-02, -2.5495e-02,\n",
      "         -1.8773e-02,  1.3006e-02,  1.9545e-02, -3.9012e-02,  2.0732e-02,\n",
      "         -4.3331e-02,  2.2042e-02, -9.6622e-03,  1.9943e-02, -2.7824e-02,\n",
      "          2.4501e-02, -8.6986e-03,  4.0863e-03, -2.0890e-03, -2.3289e-02,\n",
      "          3.9830e-02, -3.3027e-02,  2.2387e-02,  2.7746e-02, -3.4630e-02,\n",
      "          3.2229e-02,  2.1886e-02, -4.3483e-02,  3.0745e-03,  3.4431e-04,\n",
      "          3.7932e-02,  1.8418e-02, -2.8787e-02,  6.5348e-03,  1.4379e-02,\n",
      "          5.7333e-03,  3.0214e-02, -1.5924e-02, -4.2415e-02, -3.8987e-02,\n",
      "         -6.4284e-03, -4.0824e-02,  8.3482e-03,  1.3949e-02, -3.0513e-02,\n",
      "         -3.3932e-02,  1.7137e-02,  2.1852e-02,  4.3608e-02,  1.7085e-02,\n",
      "          3.1011e-02,  9.6822e-03, -2.7382e-02, -2.9691e-02, -1.3091e-02,\n",
      "          1.2512e-02,  2.5281e-02,  1.4982e-03, -2.5044e-02, -3.7335e-02,\n",
      "          2.3636e-02,  4.2421e-02,  1.2510e-03,  3.0346e-02, -2.8594e-02,\n",
      "          3.1263e-02,  6.7748e-03]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0067], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print('input_size: ', input_image.size())\n",
    "\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print('flatten_size: ', flat_image.size())\n",
    "\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print('hidden1_size: ', hidden1.size())\n",
    "\n",
    "hidden1 = nn.ReLU()(hidden1) # 激活层\n",
    "\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "\n",
    "print('logits_size: ', logits.size())\n",
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "print(pred_probab)\n",
    "print('pred_probab_size: ', pred_probab.size())\n",
    "\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param} \\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b8bdd4e700647ba2b08c59e5df8b7da1dcf50a218bcd4c1bcd9b3dc92e8788e5"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}